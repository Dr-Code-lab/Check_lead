from nltk.tokenize import word_tokenize


def tokenization(message):
    """Just tokenize text - split text to text units"""
    return word_tokenize(message)
